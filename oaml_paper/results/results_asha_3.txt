Initial model is AdaBoostClassifier(KNNClassifier) and hyperparameters are: {'model': (<class 'river.neighbors.knn_classifier.KNNClassifier'>, {'n_neighbors': 5, 'window_size': 1000, 'leaf_size': 30, 'p': 2, 'weighted': True}), 'n_models': 13, 'seed': None}
Test batch - 6000 with Accuracy: 71.60%
Test batch - 7000 with Accuracy: 73.35%
Test batch - 8000 with Accuracy: 72.87%
Test batch - 9000 with Accuracy: 72.70%
Test batch - 10000 with Accuracy: 72.54%
Change detected at data point 10897 and current performance is at Accuracy: 72.49%
Current model is LeveragingBaggingClassifier(LogisticRegression) and hyperparameters are: {'model': (<class 'river.linear_model.glm.LogisticRegression'>, {'optimizer': (<class 'river.optim.sgd.SGD'>, {'lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01})}), 'loss': (<class 'river.optim.losses.Log'>, {'weight_pos': 1.0, 'weight_neg': 1.0}), 'l2': 0.0, 'intercept_init': 0.0, 'intercept_lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01}), 'clip_gradient': 1000000000000.0, 'initializer': (<class 'river.optim.initializers.Zeros'>, {})}), 'n_models': 6, 'w': 4, 'adwin_delta': 0.01, 'bagging_method': 'subag', 'seed': None}
Test batch - 11000 with Accuracy: 72.50%
Test batch - 12000 with Accuracy: 74.30%
Change detected at data point 12633 and current performance is at Accuracy: 75.04%
Current model is AdaptiveRandomForestClassifier and hyperparameters are: {'n_models': 8, 'max_features': 100, 'lambda_value': 9, 'metric': (<class 'river.metrics.accuracy.Accuracy'>, {'cm': }), 'disable_weighted_vote': False, 'drift_detector': (<class 'river.drift.adwin.ADWIN'>, {'delta': 0.001}), 'warning_detector': (<class 'river.drift.adwin.ADWIN'>, {'delta': 0.01}), 'grace_period': 63, 'max_depth': None, 'split_criterion': 'info_gain', 'split_confidence': 0.01, 'tie_threshold': 0.06999999999999999, 'leaf_prediction': 'mc', 'nb_threshold': 0, 'nominal_attributes': None, 'splitter': None, 'binary_split': False, 'max_size': 32, 'memory_estimate_period': 2000000, 'stop_mem_management': False, 'remove_poor_attrs': False, 'merit_preprune': True, 'seed': None}
Test batch - 13000 with Accuracy: 75.54%
Test batch - 14000 with Accuracy: 76.61%
Change detected at data point 14306 and current performance is at Accuracy: 76.92%
Current model is LeveragingBaggingClassifier(Perceptron) and hyperparameters are: {'model': (<class 'river.linear_model.glm.Perceptron'>, {'l2': 0.0, 'clip_gradient': 1000000000000.0, 'initializer': (<class 'river.optim.initializers.Zeros'>, {})}), 'n_models': 17, 'w': 9, 'adwin_delta': 0.005, 'bagging_method': 'wt', 'seed': None}
Test batch - 15000 with Accuracy: 77.18%
Change detected at data point 15349 and current performance is at Accuracy: 77.18%
Current model is HoeffdingAdaptiveTreeClassifier and hyperparameters are: {'grace_period': 103, 'max_depth': inf, 'split_criterion': 'hellinger', 'split_confidence': 0.01, 'tie_threshold': 0.03, 'leaf_prediction': 'nba', 'nb_threshold': 0, 'nominal_attributes': None, 'splitter': (<class 'river.tree.splitter.gaussian_splitter.GaussianSplitter'>, {'n_splits': 10}), 'bootstrap_sampling': False, 'drift_window_threshold': 200, 'adwin_confidence': 0.0002, 'binary_split': False, 'max_size': 100, 'memory_estimate_period': 1000000, 'stop_mem_management': False, 'remove_poor_attrs': False, 'merit_preprune': True, 'seed': None}
Test batch - 16000 with Accuracy: 77.40%
Change detected at data point 16401 and current performance is at Accuracy: 77.44%
Current model is LeveragingBaggingClassifier(LogisticRegression) and hyperparameters are: {'model': (<class 'river.linear_model.glm.LogisticRegression'>, {'optimizer': (<class 'river.optim.sgd.SGD'>, {'lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01})}), 'loss': (<class 'river.optim.losses.Log'>, {'weight_pos': 1.0, 'weight_neg': 1.0}), 'l2': 0.0, 'intercept_init': 0.0, 'intercept_lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01}), 'clip_gradient': 1000000000000.0, 'initializer': (<class 'river.optim.initializers.Zeros'>, {})}), 'n_models': 7, 'w': 6, 'adwin_delta': 0.002, 'bagging_method': 'half', 'seed': None}
Test batch - 17000 with Accuracy: 77.79%
Test batch - 18000 with Accuracy: 78.34%
Test batch - 19000 with Accuracy: 78.76%
Test batch - 20000 with Accuracy: 79.13%
Test batch - 21000 with Accuracy: 79.45%
Test batch - 22000 with Accuracy: 79.81%
Test batch - 23000 with Accuracy: 79.96%
Test batch - 24000 with Accuracy: 80.21%
Test batch - 25000 with Accuracy: 80.37%
Test batch - 26000 with Accuracy: 80.49%
Test batch - 27000 with Accuracy: 80.67%
Test batch - 28000 with Accuracy: 80.81%
Test batch - 29000 with Accuracy: 80.93%
Test batch - 30000 with Accuracy: 81.11%
Test batch - 31000 with Accuracy: 81.26%
Test batch - 32000 with Accuracy: 81.36%
Test batch - 33000 with Accuracy: 81.49%
Test batch - 34000 with Accuracy: 81.57%
Test batch - 35000 with Accuracy: 81.69%
Test batch - 36000 with Accuracy: 81.73%
Test batch - 37000 with Accuracy: 81.82%
Test batch - 38000 with Accuracy: 81.90%
Test batch - 39000 with Accuracy: 81.98%
Test batch - 40000 with Accuracy: 82.03%
Test batch - 41000 with Accuracy: 82.14%
Test batch - 42000 with Accuracy: 82.20%
Test batch - 43000 with Accuracy: 82.33%
Test batch - 44000 with Accuracy: 82.40%
Test batch - 45000 with Accuracy: 82.50%
Test batch - 46000 with Accuracy: 82.55%
Test batch - 47000 with Accuracy: 82.66%
Test batch - 48000 with Accuracy: 82.73%
Test batch - 49000 with Accuracy: 82.80%
Test batch - 50000 with Accuracy: 82.79%
Test batch - 51000 with Accuracy: 82.81%
Test batch - 52000 with Accuracy: 82.84%
Test batch - 53000 with Accuracy: 82.88%
Test batch - 54000 with Accuracy: 82.93%
Test batch - 55000 with Accuracy: 82.98%
Test batch - 56000 with Accuracy: 83.01%
Test batch - 57000 with Accuracy: 83.06%
Test batch - 58000 with Accuracy: 83.11%
Test batch - 59000 with Accuracy: 83.16%
Test batch - 60000 with Accuracy: 83.22%
Test batch - 61000 with Accuracy: 83.26%
Test batch - 62000 with Accuracy: 83.28%
Test batch - 63000 with Accuracy: 83.31%
Test batch - 64000 with Accuracy: 83.36%
Test batch - 65000 with Accuracy: 83.40%
Test batch - 66000 with Accuracy: 83.43%
No drift but retraining point 66402 and current performance is at Accuracy: 83.44%
Current model is AdaBoostClassifier(LogisticRegression) and hyperparameters are: {'model': (<class 'river.linear_model.glm.LogisticRegression'>, {'optimizer': (<class 'river.optim.sgd.SGD'>, {'lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01})}), 'loss': (<class 'river.optim.losses.Log'>, {'weight_pos': 1.0, 'weight_neg': 1.0}), 'l2': 0.0, 'intercept_init': 0.0, 'intercept_lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01}), 'clip_gradient': 1000000000000.0, 'initializer': (<class 'river.optim.initializers.Zeros'>, {})}), 'n_models': 17, 'seed': None}
Test batch - 67000 with Accuracy: 83.40%
Test batch - 68000 with Accuracy: 83.35%
Test batch - 69000 with Accuracy: 83.29%
Test batch - 70000 with Accuracy: 83.24%
Test batch - 71000 with Accuracy: 83.19%
Test batch - 72000 with Accuracy: 83.11%
Test batch - 73000 with Accuracy: 83.04%
Test batch - 74000 with Accuracy: 83.01%
Test batch - 75000 with Accuracy: 82.93%
Test batch - 76000 with Accuracy: 82.87%
Test batch - 77000 with Accuracy: 82.83%
Test batch - 78000 with Accuracy: 82.74%
Test batch - 79000 with Accuracy: 82.67%
Test batch - 80000 with Accuracy: 82.63%
Test batch - 81000 with Accuracy: 82.54%
Test batch - 82000 with Accuracy: 82.51%
Test batch - 83000 with Accuracy: 82.45%
Test batch - 84000 with Accuracy: 82.42%
Test batch - 85000 with Accuracy: 82.35%
Test batch - 86000 with Accuracy: 82.32%
Test batch - 87000 with Accuracy: 82.27%
Test batch - 88000 with Accuracy: 82.26%
Test batch - 89000 with Accuracy: 82.22%
Test batch - 90000 with Accuracy: 82.18%
Test batch - 91000 with Accuracy: 82.12%
Test batch - 92000 with Accuracy: 82.08%
Test batch - 93000 with Accuracy: 82.03%
Change detected at data point 93016 and current performance is at Accuracy: 82.03%
Current model is Binarizer | ADWINBaggingClassifier(Perceptron) and hyperparameters are: {'Binarizer': {'threshold': 0.4, 'dtype': <class 'bool'>}, 'ADWINBaggingClassifier': {'model': (<class 'river.linear_model.glm.Perceptron'>, {'l2': 0.0, 'clip_gradient': 1000000000000.0, 'initializer': (<class 'river.optim.initializers.Zeros'>, {})}), 'n_models': 10, 'seed': None}}
Test batch - 94000 with Accuracy: 82.01%
Change detected at data point 94174 and current performance is at Accuracy: 82.01%
Current model is HoeffdingAdaptiveTreeClassifier and hyperparameters are: {'grace_period': 108, 'max_depth': inf, 'split_criterion': 'hellinger', 'split_confidence': 0.0001, 'tie_threshold': 0.049999999999999996, 'leaf_prediction': 'nba', 'nb_threshold': 40, 'nominal_attributes': None, 'splitter': (<class 'river.tree.splitter.gaussian_splitter.GaussianSplitter'>, {'n_splits': 10}), 'bootstrap_sampling': False, 'drift_window_threshold': 300, 'adwin_confidence': 0.002, 'binary_split': False, 'max_size': 100, 'memory_estimate_period': 1000000, 'stop_mem_management': False, 'remove_poor_attrs': False, 'merit_preprune': True, 'seed': None}
Test batch - 95000 with Accuracy: 82.00%
Change detected at data point 95217 and current performance is at Accuracy: 81.99%
Current model is AdaBoostClassifier(HoeffdingTreeClassifier) and hyperparameters are: {'model': (<class 'river.tree.hoeffding_tree_classifier.HoeffdingTreeClassifier'>, {'grace_period': 200, 'max_depth': inf, 'split_criterion': 'info_gain', 'split_confidence': 1e-07, 'tie_threshold': 0.05, 'leaf_prediction': 'nba', 'nb_threshold': 0, 'nominal_attributes': None, 'splitter': (<class 'river.tree.splitter.gaussian_splitter.GaussianSplitter'>, {'n_splits': 10}), 'binary_split': False, 'max_size': 100, 'memory_estimate_period': 1000000, 'stop_mem_management': False, 'remove_poor_attrs': False, 'merit_preprune': True}), 'n_models': 18, 'seed': None}
Test batch - 96000 with Accuracy: 81.99%
Change detected at data point 96370 and current performance is at Accuracy: 82.01%
Current model is ADWINBaggingClassifier(LogisticRegression) and hyperparameters are: {'model': (<class 'river.linear_model.glm.LogisticRegression'>, {'optimizer': (<class 'river.optim.sgd.SGD'>, {'lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01})}), 'loss': (<class 'river.optim.losses.Log'>, {'weight_pos': 1.0, 'weight_neg': 1.0}), 'l2': 0.0, 'intercept_init': 0.0, 'intercept_lr': (<class 'river.optim.schedulers.Constant'>, {'learning_rate': 0.01}), 'clip_gradient': 1000000000000.0, 'initializer': (<class 'river.optim.initializers.Zeros'>, {})}), 'n_models': 19, 'seed': None}
Test batch - 97000 with Accuracy: 82.03%
Change detected at data point 97389 and current performance is at Accuracy: 82.05%
Current model is LeveragingBaggingClassifier(HoeffdingTreeClassifier) and hyperparameters are: {'model': (<class 'river.tree.hoeffding_tree_classifier.HoeffdingTreeClassifier'>, {'grace_period': 200, 'max_depth': inf, 'split_criterion': 'info_gain', 'split_confidence': 1e-07, 'tie_threshold': 0.05, 'leaf_prediction': 'nba', 'nb_threshold': 0, 'nominal_attributes': None, 'splitter': (<class 'river.tree.splitter.gaussian_splitter.GaussianSplitter'>, {'n_splits': 10}), 'binary_split': False, 'max_size': 100, 'memory_estimate_period': 1000000, 'stop_mem_management': False, 'remove_poor_attrs': False, 'merit_preprune': True}), 'n_models': 2, 'w': 1, 'adwin_delta': 0.01, 'bagging_method': 'wt', 'seed': None}
Test batch - 98000 with Accuracy: 82.05%