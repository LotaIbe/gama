AutOL_streams_ensemble.py
Data stream is data_streams/SEA_Abrubt_5.arff.
Initial batch size is 5000.
Sliding window size is 5000.
Gama performance metric is accuracy.
Online performance metric is Accuracy: 0.00%.
Time budget for GAMA is 1800.
Search algorithm for GAMA is AsyncEA().

Initial model is AdaptiveRandomForestClassifier and hyperparameters are: {'n_models': 5, 'max_features': 3, 'lambda_value': 5, 'metric': (<class 'river.metrics.accuracy.Accuracy'>, {'cm': }), 'disable_weighted_vote': False, 'drift_detector': (<class 'river.drift.adwin.ADWIN'>, {'delta': 0.001}), 'warning_detector': (<class 'river.drift.adwin.ADWIN'>, {'delta': 0.01}), 'grace_period': 99, 'max_depth': None, 'split_criterion': 'info_gain', 'split_confidence': 1e-09, 'tie_threshold': 0.03, 'leaf_prediction': 'nba', 'nb_threshold': 10, 'nominal_attributes': None, 'splitter': None, 'binary_split': False, 'max_size': 32, 'memory_estimate_period': 2000000, 'stop_mem_management': False, 'remove_poor_attrs': False, 'merit_preprune': True, 'seed': None}
Test batch - 6000 with Accuracy: 87.10%
Change detected at data point 6098 and current performance is at Accuracy: 86.98%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [AdaptiveRandomForestClassifier (
  n_models=5
  max_features=3
  lambda_value=5
  metric=Accuracy (
    cm=ConfusionMatrix ()
  )
  disable_weighted_vote=False
  drift_detector=ADWIN (
    delta=0.001
  )
  warning_detector=ADWIN (
    delta=0.01
  )
  grace_period=99
  max_depth=None
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.03
  leaf_prediction="nba"
  nb_threshold=10
  nominal_attributes=None
  splitter=None
  binary_split=False
  max_size=32
  memory_estimate_period=2000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
)], 'use_probabilities': True}
Test batch - 7000 with Accuracy: 84.75%
Test batch - 8000 with Accuracy: 83.87%
Test batch - 9000 with Accuracy: 83.33%
Test batch - 10000 with Accuracy: 82.92%
Test batch - 11000 with Accuracy: 83.08%
Test batch - 12000 with Accuracy: 82.76%
Test batch - 13000 with Accuracy: 82.36%
Test batch - 14000 with Accuracy: 82.22%
Test batch - 15000 with Accuracy: 82.25%
Test batch - 16000 with Accuracy: 82.21%
Test batch - 17000 with Accuracy: 82.27%
Test batch - 18000 with Accuracy: 82.27%
Test batch - 19000 with Accuracy: 82.31%
Test batch - 20000 with Accuracy: 82.19%
Test batch - 21000 with Accuracy: 82.08%
Test batch - 22000 with Accuracy: 82.05%
Test batch - 23000 with Accuracy: 82.05%
Test batch - 24000 with Accuracy: 82.08%
Test batch - 25000 with Accuracy: 82.14%
Test batch - 26000 with Accuracy: 82.10%
Test batch - 27000 with Accuracy: 82.07%
Test batch - 28000 with Accuracy: 82.14%
Test batch - 29000 with Accuracy: 82.13%
Test batch - 30000 with Accuracy: 82.07%
Test batch - 31000 with Accuracy: 82.06%
Test batch - 32000 with Accuracy: 82.04%
Test batch - 33000 with Accuracy: 82.00%
Test batch - 34000 with Accuracy: 82.04%
Test batch - 35000 with Accuracy: 82.12%
Test batch - 36000 with Accuracy: 82.10%
Test batch - 37000 with Accuracy: 82.10%
Test batch - 38000 with Accuracy: 82.09%
Test batch - 39000 with Accuracy: 82.14%
Test batch - 40000 with Accuracy: 82.17%
Test batch - 41000 with Accuracy: 82.17%
Test batch - 42000 with Accuracy: 82.18%
Test batch - 43000 with Accuracy: 82.19%
Test batch - 44000 with Accuracy: 82.11%
Test batch - 45000 with Accuracy: 82.08%
Test batch - 46000 with Accuracy: 82.07%
Test batch - 47000 with Accuracy: 82.01%
Test batch - 48000 with Accuracy: 81.97%
Test batch - 49000 with Accuracy: 82.00%
Test batch - 50000 with Accuracy: 82.03%
Test batch - 51000 with Accuracy: 82.00%
Test batch - 52000 with Accuracy: 81.99%
Test batch - 53000 with Accuracy: 81.99%
Test batch - 54000 with Accuracy: 81.94%
Test batch - 55000 with Accuracy: 81.94%
Test batch - 56000 with Accuracy: 81.94%
No drift but retraining point 56099 and current performance is at Accuracy: 81.94%
Online model is updated with latest AutoML pipeline.
Current model is LeveragingBaggingClassifier(KNNClassifier) and hyperparameters are: {'model': (<class 'river.neighbors.knn_classifier.KNNClassifier'>, {'n_neighbors': 5, 'window_size': 1000, 'leaf_size': 30, 'p': 2, 'weighted': True}), 'n_models': 8, 'w': 8, 'adwin_delta': 0.005, 'bagging_method': 'wt', 'seed': None}
Test batch - 57000 with Accuracy: 81.96%
Test batch - 58000 with Accuracy: 81.97%
Test batch - 59000 with Accuracy: 81.94%
Test batch - 60000 with Accuracy: 81.89%
Test batch - 61000 with Accuracy: 81.91%
Test batch - 62000 with Accuracy: 81.91%
Test batch - 63000 with Accuracy: 81.92%
Test batch - 64000 with Accuracy: 81.92%
Test batch - 65000 with Accuracy: 81.95%
Test batch - 66000 with Accuracy: 81.93%
Test batch - 67000 with Accuracy: 81.94%
Test batch - 68000 with Accuracy: 81.92%
Test batch - 69000 with Accuracy: 81.95%
Test batch - 70000 with Accuracy: 81.93%
Test batch - 71000 with Accuracy: 81.93%
Test batch - 72000 with Accuracy: 81.92%
Test batch - 73000 with Accuracy: 81.91%
Test batch - 74000 with Accuracy: 81.91%
Test batch - 75000 with Accuracy: 81.91%
Test batch - 76000 with Accuracy: 81.92%
Test batch - 77000 with Accuracy: 81.96%
Test batch - 78000 with Accuracy: 82.03%
Test batch - 79000 with Accuracy: 82.03%
Test batch - 80000 with Accuracy: 82.03%
Test batch - 81000 with Accuracy: 82.02%
Test batch - 82000 with Accuracy: 82.05%
Test batch - 83000 with Accuracy: 82.03%
Test batch - 84000 with Accuracy: 82.05%
Test batch - 85000 with Accuracy: 82.05%
Test batch - 86000 with Accuracy: 82.02%
Test batch - 87000 with Accuracy: 82.04%
Test batch - 88000 with Accuracy: 82.03%
Test batch - 89000 with Accuracy: 81.98%
Test batch - 90000 with Accuracy: 81.99%
Test batch - 91000 with Accuracy: 82.00%
Test batch - 92000 with Accuracy: 81.97%
Test batch - 93000 with Accuracy: 81.97%
Test batch - 94000 with Accuracy: 81.95%
Test batch - 95000 with Accuracy: 81.95%
Test batch - 96000 with Accuracy: 81.93%
Test batch - 97000 with Accuracy: 81.95%
Test batch - 98000 with Accuracy: 81.96%
Test batch - 99000 with Accuracy: 81.99%
Test batch - 100000 with Accuracy: 81.98%
Test batch - 101000 with Accuracy: 81.99%
Test batch - 102000 with Accuracy: 82.02%
Test batch - 103000 with Accuracy: 82.05%
Test batch - 104000 with Accuracy: 82.04%
Test batch - 105000 with Accuracy: 82.03%
Test batch - 106000 with Accuracy: 82.02%
No drift but retraining point 106100 and current performance is at Accuracy: 82.01%
Online model is updated with latest AutoML pipeline.
Current model is HoeffdingAdaptiveTreeClassifier and hyperparameters are: {'grace_period': 268, 'max_depth': inf, 'split_criterion': 'hellinger', 'split_confidence': 0.01, 'tie_threshold': 0.06999999999999999, 'leaf_prediction': 'nba', 'nb_threshold': 30, 'nominal_attributes': None, 'splitter': (<class 'river.tree.splitter.gaussian_splitter.GaussianSplitter'>, {'n_splits': 10}), 'bootstrap_sampling': False, 'drift_window_threshold': 300, 'adwin_confidence': 0.0002, 'binary_split': False, 'max_size': 100, 'memory_estimate_period': 1000000, 'stop_mem_management': False, 'remove_poor_attrs': False, 'merit_preprune': True, 'seed': None}
Test batch - 107000 with Accuracy: 82.06%
Test batch - 108000 with Accuracy: 82.09%
Test batch - 109000 with Accuracy: 82.14%
Test batch - 110000 with Accuracy: 82.18%
Test batch - 111000 with Accuracy: 82.24%
Test batch - 112000 with Accuracy: 82.28%
Test batch - 113000 with Accuracy: 82.33%
Test batch - 114000 with Accuracy: 82.38%
Test batch - 115000 with Accuracy: 82.44%
Test batch - 116000 with Accuracy: 82.49%
Test batch - 117000 with Accuracy: 82.55%
Test batch - 118000 with Accuracy: 82.59%
Test batch - 119000 with Accuracy: 82.65%
Test batch - 120000 with Accuracy: 82.70%
Test batch - 121000 with Accuracy: 82.75%
Test batch - 122000 with Accuracy: 82.81%
Test batch - 123000 with Accuracy: 82.86%
Test batch - 124000 with Accuracy: 82.92%
Test batch - 125000 with Accuracy: 82.97%
Test batch - 126000 with Accuracy: 83.00%
Test batch - 127000 with Accuracy: 83.04%
Test batch - 128000 with Accuracy: 83.08%
Test batch - 129000 with Accuracy: 83.12%
Test batch - 130000 with Accuracy: 83.16%
Test batch - 131000 with Accuracy: 83.20%
Test batch - 132000 with Accuracy: 83.25%
Test batch - 133000 with Accuracy: 83.29%
Test batch - 134000 with Accuracy: 83.32%
Test batch - 135000 with Accuracy: 83.37%
Test batch - 136000 with Accuracy: 83.41%
Test batch - 137000 with Accuracy: 83.44%
Test batch - 138000 with Accuracy: 83.48%
Test batch - 139000 with Accuracy: 83.51%
Test batch - 140000 with Accuracy: 83.55%
Test batch - 141000 with Accuracy: 83.59%
Test batch - 142000 with Accuracy: 83.62%
Test batch - 143000 with Accuracy: 83.66%
Test batch - 144000 with Accuracy: 83.68%
Test batch - 145000 with Accuracy: 83.72%
Test batch - 146000 with Accuracy: 83.76%
Test batch - 147000 with Accuracy: 83.80%
Test batch - 148000 with Accuracy: 83.82%
Test batch - 149000 with Accuracy: 83.85%
Test batch - 150000 with Accuracy: 83.88%
Test batch - 151000 with Accuracy: 83.92%
Test batch - 152000 with Accuracy: 83.95%
Test batch - 153000 with Accuracy: 84.00%
Test batch - 154000 with Accuracy: 84.03%
Test batch - 155000 with Accuracy: 84.06%
Test batch - 156000 with Accuracy: 84.10%
No drift but retraining point 156101 and current performance is at Accuracy: 84.10%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [AdaptiveRandomForestClassifier (
  n_models=5
  max_features=3
  lambda_value=5
  metric=Accuracy (
    cm=ConfusionMatrix ()
  )
  disable_weighted_vote=False
  drift_detector=ADWIN (
    delta=0.001
  )
  warning_detector=ADWIN (
    delta=0.01
  )
  grace_period=99
  max_depth=None
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.03
  leaf_prediction="nba"
  nb_threshold=10
  nominal_attributes=None
  splitter=None
  binary_split=False
  max_size=32
  memory_estimate_period=2000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=8
  w=8
  adwin_delta=0.005
  bagging_method="wt"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=268
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.07
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), AdaBoostClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  seed=None
)], 'use_probabilities': True}
Test batch - 157000 with Accuracy: 84.12%
Test batch - 158000 with Accuracy: 84.15%
Test batch - 159000 with Accuracy: 84.18%
Test batch - 160000 with Accuracy: 84.19%
Test batch - 161000 with Accuracy: 84.22%
Test batch - 162000 with Accuracy: 84.24%
Test batch - 163000 with Accuracy: 84.26%
Test batch - 164000 with Accuracy: 84.27%
Test batch - 165000 with Accuracy: 84.29%
Test batch - 166000 with Accuracy: 84.32%
Test batch - 167000 with Accuracy: 84.34%
Test batch - 168000 with Accuracy: 84.36%
Test batch - 169000 with Accuracy: 84.39%
Test batch - 170000 with Accuracy: 84.41%
Test batch - 171000 with Accuracy: 84.44%
Test batch - 172000 with Accuracy: 84.46%
Test batch - 173000 with Accuracy: 84.49%
Test batch - 174000 with Accuracy: 84.51%
Test batch - 175000 with Accuracy: 84.53%
Test batch - 176000 with Accuracy: 84.55%
Test batch - 177000 with Accuracy: 84.57%
Test batch - 178000 with Accuracy: 84.60%
Test batch - 179000 with Accuracy: 84.61%
Test batch - 180000 with Accuracy: 84.64%
Test batch - 181000 with Accuracy: 84.66%
Test batch - 182000 with Accuracy: 84.67%
Test batch - 183000 with Accuracy: 84.69%
Test batch - 184000 with Accuracy: 84.71%
Test batch - 185000 with Accuracy: 84.73%
Test batch - 186000 with Accuracy: 84.75%
Test batch - 187000 with Accuracy: 84.76%
Test batch - 188000 with Accuracy: 84.78%
Test batch - 189000 with Accuracy: 84.80%
Test batch - 190000 with Accuracy: 84.83%
Test batch - 191000 with Accuracy: 84.84%
Test batch - 192000 with Accuracy: 84.86%
Test batch - 193000 with Accuracy: 84.87%
Test batch - 194000 with Accuracy: 84.88%
Test batch - 195000 with Accuracy: 84.89%
Test batch - 196000 with Accuracy: 84.90%
Test batch - 197000 with Accuracy: 84.92%
Test batch - 198000 with Accuracy: 84.93%
Test batch - 199000 with Accuracy: 84.94%
Test batch - 200000 with Accuracy: 84.97%
Test batch - 201000 with Accuracy: 84.98%
Test batch - 202000 with Accuracy: 85.00%
Test batch - 203000 with Accuracy: 85.02%
Test batch - 204000 with Accuracy: 85.04%
Test batch - 205000 with Accuracy: 85.05%
Test batch - 206000 with Accuracy: 85.07%
No drift but retraining point 206102 and current performance is at Accuracy: 85.07%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [AdaptiveRandomForestClassifier (
  n_models=5
  max_features=3
  lambda_value=5
  metric=Accuracy (
    cm=ConfusionMatrix ()
  )
  disable_weighted_vote=False
  drift_detector=ADWIN (
    delta=0.001
  )
  warning_detector=ADWIN (
    delta=0.01
  )
  grace_period=99
  max_depth=None
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.03
  leaf_prediction="nba"
  nb_threshold=10
  nominal_attributes=None
  splitter=None
  binary_split=False
  max_size=32
  memory_estimate_period=2000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=8
  w=8
  adwin_delta=0.005
  bagging_method="wt"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=268
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.07
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), AdaBoostClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=137
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=1e-07
  tie_threshold=0.06
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
)], 'use_probabilities': True}
Test batch - 207000 with Accuracy: 85.08%
Test batch - 208000 with Accuracy: 85.10%
Test batch - 209000 with Accuracy: 85.12%
Test batch - 210000 with Accuracy: 85.14%
Test batch - 211000 with Accuracy: 85.14%
Test batch - 212000 with Accuracy: 85.17%
Test batch - 213000 with Accuracy: 85.18%
Test batch - 214000 with Accuracy: 85.21%
Test batch - 215000 with Accuracy: 85.22%
Test batch - 216000 with Accuracy: 85.24%
Test batch - 217000 with Accuracy: 85.25%
Test batch - 218000 with Accuracy: 85.27%
Test batch - 219000 with Accuracy: 85.29%
Test batch - 220000 with Accuracy: 85.31%
Test batch - 221000 with Accuracy: 85.33%
Test batch - 222000 with Accuracy: 85.34%
Test batch - 223000 with Accuracy: 85.35%
Test batch - 224000 with Accuracy: 85.36%
Test batch - 225000 with Accuracy: 85.37%
Test batch - 226000 with Accuracy: 85.39%
Test batch - 227000 with Accuracy: 85.41%
Test batch - 228000 with Accuracy: 85.43%
Test batch - 229000 with Accuracy: 85.44%
Test batch - 230000 with Accuracy: 85.46%
Test batch - 231000 with Accuracy: 85.47%
Test batch - 232000 with Accuracy: 85.48%
Test batch - 233000 with Accuracy: 85.49%
Test batch - 234000 with Accuracy: 85.52%
Test batch - 235000 with Accuracy: 85.54%
Test batch - 236000 with Accuracy: 85.55%
Test batch - 237000 with Accuracy: 85.56%
Test batch - 238000 with Accuracy: 85.57%
Test batch - 239000 with Accuracy: 85.58%
Test batch - 240000 with Accuracy: 85.60%
Test batch - 241000 with Accuracy: 85.62%
Test batch - 242000 with Accuracy: 85.63%
Test batch - 243000 with Accuracy: 85.64%
Test batch - 244000 with Accuracy: 85.66%
Test batch - 245000 with Accuracy: 85.68%
Test batch - 246000 with Accuracy: 85.70%
Test batch - 247000 with Accuracy: 85.72%
Test batch - 248000 with Accuracy: 85.72%
Test batch - 249000 with Accuracy: 85.74%
Test batch - 250000 with Accuracy: 85.76%
Test batch - 251000 with Accuracy: 85.71%
Test batch - 252000 with Accuracy: 85.69%
Test batch - 253000 with Accuracy: 85.68%
Test batch - 254000 with Accuracy: 85.68%
Test batch - 255000 with Accuracy: 85.69%
Test batch - 256000 with Accuracy: 85.70%
No drift but retraining point 256103 and current performance is at Accuracy: 85.70%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [AdaptiveRandomForestClassifier (
  n_models=5
  max_features=3
  lambda_value=5
  metric=Accuracy (
    cm=ConfusionMatrix ()
  )
  disable_weighted_vote=False
  drift_detector=ADWIN (
    delta=0.001
  )
  warning_detector=ADWIN (
    delta=0.01
  )
  grace_period=99
  max_depth=None
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.03
  leaf_prediction="nba"
  nb_threshold=10
  nominal_attributes=None
  splitter=None
  binary_split=False
  max_size=32
  memory_estimate_period=2000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=8
  w=8
  adwin_delta=0.005
  bagging_method="wt"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=268
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.07
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), AdaBoostClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=137
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=1e-07
  tie_threshold=0.06
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=165
  max_depth=inf
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.06
  leaf_prediction="mc"
  nb_threshold=20
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=100
  adwin_confidence=0.002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
)], 'use_probabilities': True}
Test batch - 257000 with Accuracy: 85.71%
Test batch - 258000 with Accuracy: 85.72%
Test batch - 259000 with Accuracy: 85.72%
Test batch - 260000 with Accuracy: 85.73%
Test batch - 261000 with Accuracy: 85.74%
Test batch - 262000 with Accuracy: 85.75%
Test batch - 263000 with Accuracy: 85.76%
Test batch - 264000 with Accuracy: 85.77%
Test batch - 265000 with Accuracy: 85.78%
Test batch - 266000 with Accuracy: 85.79%
Test batch - 267000 with Accuracy: 85.80%
Test batch - 268000 with Accuracy: 85.81%
Test batch - 269000 with Accuracy: 85.83%
Test batch - 270000 with Accuracy: 85.83%
Test batch - 271000 with Accuracy: 85.84%
Test batch - 272000 with Accuracy: 85.86%
Test batch - 273000 with Accuracy: 85.88%
Test batch - 274000 with Accuracy: 85.88%
Test batch - 275000 with Accuracy: 85.90%
Test batch - 276000 with Accuracy: 85.91%
Test batch - 277000 with Accuracy: 85.91%
Test batch - 278000 with Accuracy: 85.93%
Test batch - 279000 with Accuracy: 85.94%
Test batch - 280000 with Accuracy: 85.95%
Test batch - 281000 with Accuracy: 85.96%
Test batch - 282000 with Accuracy: 85.97%
Test batch - 283000 with Accuracy: 85.98%
Test batch - 284000 with Accuracy: 86.00%
Test batch - 285000 with Accuracy: 86.01%
Test batch - 286000 with Accuracy: 86.01%
Test batch - 287000 with Accuracy: 86.03%
Test batch - 288000 with Accuracy: 86.04%
Test batch - 289000 with Accuracy: 86.05%
Test batch - 290000 with Accuracy: 86.06%
Test batch - 291000 with Accuracy: 86.07%
Test batch - 292000 with Accuracy: 86.09%
Test batch - 293000 with Accuracy: 86.10%
Test batch - 294000 with Accuracy: 86.10%
Test batch - 295000 with Accuracy: 86.11%
Test batch - 296000 with Accuracy: 86.12%
Test batch - 297000 with Accuracy: 86.13%
Test batch - 298000 with Accuracy: 86.14%
Test batch - 299000 with Accuracy: 86.15%
Test batch - 300000 with Accuracy: 86.15%
Test batch - 301000 with Accuracy: 86.16%
Test batch - 302000 with Accuracy: 86.17%
Test batch - 303000 with Accuracy: 86.18%
Test batch - 304000 with Accuracy: 86.19%
Test batch - 305000 with Accuracy: 86.20%
Test batch - 306000 with Accuracy: 86.21%
No drift but retraining point 306104 and current performance is at Accuracy: 86.21%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [AdaptiveRandomForestClassifier (
  n_models=5
  max_features=3
  lambda_value=5
  metric=Accuracy (
    cm=ConfusionMatrix ()
  )
  disable_weighted_vote=False
  drift_detector=ADWIN (
    delta=0.001
  )
  warning_detector=ADWIN (
    delta=0.01
  )
  grace_period=99
  max_depth=None
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.03
  leaf_prediction="nba"
  nb_threshold=10
  nominal_attributes=None
  splitter=None
  binary_split=False
  max_size=32
  memory_estimate_period=2000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=8
  w=8
  adwin_delta=0.005
  bagging_method="wt"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=268
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.07
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), AdaBoostClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=137
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=1e-07
  tie_threshold=0.06
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=165
  max_depth=inf
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.06
  leaf_prediction="mc"
  nb_threshold=20
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=100
  adwin_confidence=0.002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=HoeffdingTreeClassifier (
    grace_period=200
    max_depth=inf
    split_criterion="info_gain"
    split_confidence=1e-07
    tie_threshold=0.05
    leaf_prediction="nba"
    nb_threshold=0
    nominal_attributes=None
    splitter=GaussianSplitter (
      n_splits=10
    )
    binary_split=False
    max_size=100
    memory_estimate_period=1000000
    stop_mem_management=False
    remove_poor_attrs=False
    merit_preprune=True
  )
  n_models=4
  w=3
  adwin_delta=0.002
  bagging_method="bag"
  seed=None
)], 'use_probabilities': True}
Test batch - 307000 with Accuracy: 86.22%
Test batch - 308000 with Accuracy: 86.23%
Test batch - 309000 with Accuracy: 86.24%
Test batch - 310000 with Accuracy: 86.25%
Test batch - 311000 with Accuracy: 86.26%
Test batch - 312000 with Accuracy: 86.26%
Test batch - 313000 with Accuracy: 86.27%
Test batch - 314000 with Accuracy: 86.28%
Test batch - 315000 with Accuracy: 86.29%
Test batch - 316000 with Accuracy: 86.30%
Test batch - 317000 with Accuracy: 86.31%
Test batch - 318000 with Accuracy: 86.32%
Test batch - 319000 with Accuracy: 86.33%
Test batch - 320000 with Accuracy: 86.34%
Test batch - 321000 with Accuracy: 86.34%
Test batch - 322000 with Accuracy: 86.36%
Test batch - 323000 with Accuracy: 86.36%
Test batch - 324000 with Accuracy: 86.37%
Test batch - 325000 with Accuracy: 86.38%
Test batch - 326000 with Accuracy: 86.39%
Test batch - 327000 with Accuracy: 86.40%
Test batch - 328000 with Accuracy: 86.42%
Test batch - 329000 with Accuracy: 86.42%
Test batch - 330000 with Accuracy: 86.43%
Test batch - 331000 with Accuracy: 86.44%
Test batch - 332000 with Accuracy: 86.45%
Test batch - 333000 with Accuracy: 86.46%
Test batch - 334000 with Accuracy: 86.47%
Test batch - 335000 with Accuracy: 86.48%
Test batch - 336000 with Accuracy: 86.49%
Test batch - 337000 with Accuracy: 86.50%
Test batch - 338000 with Accuracy: 86.51%
Test batch - 339000 with Accuracy: 86.51%
Test batch - 340000 with Accuracy: 86.52%
Test batch - 341000 with Accuracy: 86.53%
Test batch - 342000 with Accuracy: 86.54%
Test batch - 343000 with Accuracy: 86.55%
Test batch - 344000 with Accuracy: 86.55%
Test batch - 345000 with Accuracy: 86.56%
Test batch - 346000 with Accuracy: 86.56%
Test batch - 347000 with Accuracy: 86.57%
Test batch - 348000 with Accuracy: 86.58%
Test batch - 349000 with Accuracy: 86.59%
Test batch - 350000 with Accuracy: 86.60%
Test batch - 351000 with Accuracy: 86.61%
Test batch - 352000 with Accuracy: 86.62%
Test batch - 353000 with Accuracy: 86.64%
Test batch - 354000 with Accuracy: 86.64%
Test batch - 355000 with Accuracy: 86.65%
Test batch - 356000 with Accuracy: 86.66%
No drift but retraining point 356105 and current performance is at Accuracy: 86.66%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [AdaptiveRandomForestClassifier (
  n_models=5
  max_features=3
  lambda_value=5
  metric=Accuracy (
    cm=ConfusionMatrix ()
  )
  disable_weighted_vote=False
  drift_detector=ADWIN (
    delta=0.001
  )
  warning_detector=ADWIN (
    delta=0.01
  )
  grace_period=99
  max_depth=None
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.03
  leaf_prediction="nba"
  nb_threshold=10
  nominal_attributes=None
  splitter=None
  binary_split=False
  max_size=32
  memory_estimate_period=2000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=8
  w=8
  adwin_delta=0.005
  bagging_method="wt"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=268
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.07
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), AdaBoostClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=137
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=1e-07
  tie_threshold=0.06
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=165
  max_depth=inf
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.06
  leaf_prediction="mc"
  nb_threshold=20
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=100
  adwin_confidence=0.002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=HoeffdingTreeClassifier (
    grace_period=200
    max_depth=inf
    split_criterion="info_gain"
    split_confidence=1e-07
    tie_threshold=0.05
    leaf_prediction="nba"
    nb_threshold=0
    nominal_attributes=None
    splitter=GaussianSplitter (
      n_splits=10
    )
    binary_split=False
    max_size=100
    memory_estimate_period=1000000
    stop_mem_management=False
    remove_poor_attrs=False
    merit_preprune=True
  )
  n_models=4
  w=3
  adwin_delta=0.002
  bagging_method="bag"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=133
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.06
  leaf_prediction="nb"
  nb_threshold=10
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=200
  adwin_confidence=0.02
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
)], 'use_probabilities': True}
Test batch - 357000 with Accuracy: 86.66%
Test batch - 358000 with Accuracy: 86.66%
Test batch - 359000 with Accuracy: 86.67%
Test batch - 360000 with Accuracy: 86.67%
Test batch - 361000 with Accuracy: 86.68%
Test batch - 362000 with Accuracy: 86.69%
Test batch - 363000 with Accuracy: 86.70%
Test batch - 364000 with Accuracy: 86.70%
Test batch - 365000 with Accuracy: 86.71%
Test batch - 366000 with Accuracy: 86.72%
Test batch - 367000 with Accuracy: 86.73%
Test batch - 368000 with Accuracy: 86.74%
Test batch - 369000 with Accuracy: 86.74%
Test batch - 370000 with Accuracy: 86.75%
Test batch - 371000 with Accuracy: 86.76%
Test batch - 372000 with Accuracy: 86.77%
Test batch - 373000 with Accuracy: 86.78%
Test batch - 374000 with Accuracy: 86.79%
Test batch - 375000 with Accuracy: 86.80%
Test batch - 376000 with Accuracy: 86.81%
Test batch - 377000 with Accuracy: 86.82%
Test batch - 378000 with Accuracy: 86.82%
Test batch - 379000 with Accuracy: 86.83%
Test batch - 380000 with Accuracy: 86.83%
Test batch - 381000 with Accuracy: 86.84%
Test batch - 382000 with Accuracy: 86.85%
Test batch - 383000 with Accuracy: 86.86%
Test batch - 384000 with Accuracy: 86.86%
Test batch - 385000 with Accuracy: 86.87%
Test batch - 386000 with Accuracy: 86.88%
Test batch - 387000 with Accuracy: 86.88%
Test batch - 388000 with Accuracy: 86.89%
Test batch - 389000 with Accuracy: 86.90%
Test batch - 390000 with Accuracy: 86.90%
Test batch - 391000 with Accuracy: 86.91%
Test batch - 392000 with Accuracy: 86.92%
Test batch - 393000 with Accuracy: 86.92%
Test batch - 394000 with Accuracy: 86.93%
Test batch - 395000 with Accuracy: 86.93%
Test batch - 396000 with Accuracy: 86.94%
Test batch - 397000 with Accuracy: 86.95%
Test batch - 398000 with Accuracy: 86.95%
Test batch - 399000 with Accuracy: 86.96%
Test batch - 400000 with Accuracy: 86.96%
Test batch - 401000 with Accuracy: 86.97%
Test batch - 402000 with Accuracy: 86.98%
Test batch - 403000 with Accuracy: 86.99%
Test batch - 404000 with Accuracy: 87.00%
Test batch - 405000 with Accuracy: 87.00%
Test batch - 406000 with Accuracy: 87.01%
No drift but retraining point 406106 and current performance is at Accuracy: 87.01%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [AdaptiveRandomForestClassifier (
  n_models=5
  max_features=3
  lambda_value=5
  metric=Accuracy (
    cm=ConfusionMatrix ()
  )
  disable_weighted_vote=False
  drift_detector=ADWIN (
    delta=0.001
  )
  warning_detector=ADWIN (
    delta=0.01
  )
  grace_period=99
  max_depth=None
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.03
  leaf_prediction="nba"
  nb_threshold=10
  nominal_attributes=None
  splitter=None
  binary_split=False
  max_size=32
  memory_estimate_period=2000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=8
  w=8
  adwin_delta=0.005
  bagging_method="wt"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=268
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.07
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), AdaBoostClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=137
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=1e-07
  tie_threshold=0.06
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=165
  max_depth=inf
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.06
  leaf_prediction="mc"
  nb_threshold=20
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=100
  adwin_confidence=0.002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=HoeffdingTreeClassifier (
    grace_period=200
    max_depth=inf
    split_criterion="info_gain"
    split_confidence=1e-07
    tie_threshold=0.05
    leaf_prediction="nba"
    nb_threshold=0
    nominal_attributes=None
    splitter=GaussianSplitter (
      n_splits=10
    )
    binary_split=False
    max_size=100
    memory_estimate_period=1000000
    stop_mem_management=False
    remove_poor_attrs=False
    merit_preprune=True
  )
  n_models=4
  w=3
  adwin_delta=0.002
  bagging_method="bag"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=133
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.06
  leaf_prediction="nb"
  nb_threshold=10
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=200
  adwin_confidence=0.02
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=19
  w=6
  adwin_delta=0.005
  bagging_method="bag"
  seed=None
)], 'use_probabilities': True}
Test batch - 407000 with Accuracy: 87.02%
Test batch - 408000 with Accuracy: 87.02%
Test batch - 409000 with Accuracy: 87.03%
Test batch - 410000 with Accuracy: 87.03%
Test batch - 411000 with Accuracy: 87.04%
Test batch - 412000 with Accuracy: 87.04%
Test batch - 413000 with Accuracy: 87.05%
Test batch - 414000 with Accuracy: 87.04%
Test batch - 415000 with Accuracy: 87.05%
Test batch - 416000 with Accuracy: 87.06%
Test batch - 417000 with Accuracy: 87.06%
Test batch - 418000 with Accuracy: 87.07%
Test batch - 419000 with Accuracy: 87.08%
Test batch - 420000 with Accuracy: 87.08%
Test batch - 421000 with Accuracy: 87.09%
Test batch - 422000 with Accuracy: 87.10%
Test batch - 423000 with Accuracy: 87.10%
Test batch - 424000 with Accuracy: 87.11%
Test batch - 425000 with Accuracy: 87.12%
Test batch - 426000 with Accuracy: 87.12%
Test batch - 427000 with Accuracy: 87.13%
Test batch - 428000 with Accuracy: 87.13%
Test batch - 429000 with Accuracy: 87.13%
Test batch - 430000 with Accuracy: 87.14%
Test batch - 431000 with Accuracy: 87.15%
Test batch - 432000 with Accuracy: 87.15%
Test batch - 433000 with Accuracy: 87.16%
Test batch - 434000 with Accuracy: 87.17%
Test batch - 435000 with Accuracy: 87.17%
Test batch - 436000 with Accuracy: 87.18%
Test batch - 437000 with Accuracy: 87.18%
Test batch - 438000 with Accuracy: 87.18%
Test batch - 439000 with Accuracy: 87.19%
Test batch - 440000 with Accuracy: 87.20%
Test batch - 441000 with Accuracy: 87.20%
Test batch - 442000 with Accuracy: 87.20%
Test batch - 443000 with Accuracy: 87.21%
Test batch - 444000 with Accuracy: 87.21%
Test batch - 445000 with Accuracy: 87.21%
Test batch - 446000 with Accuracy: 87.22%
Test batch - 447000 with Accuracy: 87.22%
Test batch - 448000 with Accuracy: 87.23%
Test batch - 449000 with Accuracy: 87.23%
Test batch - 450000 with Accuracy: 87.24%
Test batch - 451000 with Accuracy: 87.24%
Test batch - 452000 with Accuracy: 87.25%
Test batch - 453000 with Accuracy: 87.26%
Test batch - 454000 with Accuracy: 87.26%
Test batch - 455000 with Accuracy: 87.26%
Test batch - 456000 with Accuracy: 87.27%
No drift but retraining point 456107 and current performance is at Accuracy: 87.27%
Online model is updated with Backup Ensemble.
Current model is VotingClassifier and hyperparameters are: {'models': [LeveragingBaggingClassifier (
  model=Perceptron (
    l2=0.
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  w=5
  adwin_delta=0.001
  bagging_method="wt"
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=8
  w=8
  adwin_delta=0.005
  bagging_method="wt"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=268
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.07
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), AdaBoostClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=9
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=137
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=1e-07
  tie_threshold=0.06
  leaf_prediction="nba"
  nb_threshold=30
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=300
  adwin_confidence=0.0002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=165
  max_depth=inf
  split_criterion="info_gain"
  split_confidence=1e-09
  tie_threshold=0.06
  leaf_prediction="mc"
  nb_threshold=20
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=False
  drift_window_threshold=100
  adwin_confidence=0.002
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=HoeffdingTreeClassifier (
    grace_period=200
    max_depth=inf
    split_criterion="info_gain"
    split_confidence=1e-07
    tie_threshold=0.05
    leaf_prediction="nba"
    nb_threshold=0
    nominal_attributes=None
    splitter=GaussianSplitter (
      n_splits=10
    )
    binary_split=False
    max_size=100
    memory_estimate_period=1000000
    stop_mem_management=False
    remove_poor_attrs=False
    merit_preprune=True
  )
  n_models=4
  w=3
  adwin_delta=0.002
  bagging_method="bag"
  seed=None
), HoeffdingAdaptiveTreeClassifier (
  grace_period=133
  max_depth=inf
  split_criterion="hellinger"
  split_confidence=0.01
  tie_threshold=0.06
  leaf_prediction="nb"
  nb_threshold=10
  nominal_attributes=None
  splitter=GaussianSplitter (
    n_splits=10
  )
  bootstrap_sampling=True
  drift_window_threshold=200
  adwin_confidence=0.02
  binary_split=False
  max_size=100
  memory_estimate_period=1000000
  stop_mem_management=False
  remove_poor_attrs=False
  merit_preprune=True
  seed=None
), LeveragingBaggingClassifier (
  model=KNNClassifier (
    n_neighbors=5
    window_size=1000
    leaf_size=30
    p=2
    weighted=True
  )
  n_models=19
  w=6
  adwin_delta=0.005
  bagging_method="bag"
  seed=None
), LeveragingBaggingClassifier (
  model=LogisticRegression (
    optimizer=SGD (
      lr=Constant (
        learning_rate=0.01
      )
    )
    loss=Log (
      weight_pos=1.
      weight_neg=1.
    )
    l2=0.
    intercept_init=0.
    intercept_lr=Constant (
      learning_rate=0.01
    )
    clip_gradient=1e+12
    initializer=Zeros ()
  )
  n_models=11
  w=3
  adwin_delta=0.002
  bagging_method="subag"
  seed=None
)], 'use_probabilities': True}
Test batch - 457000 with Accuracy: 87.27%
Test batch - 458000 with Accuracy: 87.28%
Test batch - 459000 with Accuracy: 87.28%
Test batch - 460000 with Accuracy: 87.29%
Test batch - 461000 with Accuracy: 87.29%
Test batch - 462000 with Accuracy: 87.29%
Test batch - 463000 with Accuracy: 87.30%
Test batch - 464000 with Accuracy: 87.30%
Test batch - 465000 with Accuracy: 87.31%
Test batch - 466000 with Accuracy: 87.31%
Test batch - 467000 with Accuracy: 87.31%
Test batch - 468000 with Accuracy: 87.32%
Test batch - 469000 with Accuracy: 87.33%
Test batch - 470000 with Accuracy: 87.33%
Test batch - 471000 with Accuracy: 87.34%
Test batch - 472000 with Accuracy: 87.34%
Test batch - 473000 with Accuracy: 87.34%
Test batch - 474000 with Accuracy: 87.34%
Test batch - 475000 with Accuracy: 87.34%
Test batch - 476000 with Accuracy: 87.35%
Test batch - 477000 with Accuracy: 87.36%
Test batch - 478000 with Accuracy: 87.36%
Test batch - 479000 with Accuracy: 87.36%
Test batch - 480000 with Accuracy: 87.37%
Test batch - 481000 with Accuracy: 87.37%
Test batch - 482000 with Accuracy: 87.38%
Test batch - 483000 with Accuracy: 87.38%
Test batch - 484000 with Accuracy: 87.39%
Test batch - 485000 with Accuracy: 87.39%
Test batch - 486000 with Accuracy: 87.39%
Test batch - 487000 with Accuracy: 87.39%
Test batch - 488000 with Accuracy: 87.40%
Test batch - 489000 with Accuracy: 87.40%
Test batch - 490000 with Accuracy: 87.41%
Test batch - 491000 with Accuracy: 87.41%
Test batch - 492000 with Accuracy: 87.42%
Test batch - 493000 with Accuracy: 87.42%
Test batch - 494000 with Accuracy: 87.43%
Test batch - 495000 with Accuracy: 87.43%
Test batch - 496000 with Accuracy: 87.44%
Test batch - 497000 with Accuracy: 87.44%
Test batch - 498000 with Accuracy: 87.44%
Test batch - 499000 with Accuracy: 87.45%

